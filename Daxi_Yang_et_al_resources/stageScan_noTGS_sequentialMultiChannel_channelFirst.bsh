import java.lang.String;
import java.text.DecimalFormat;
import org.micromanager.data.SummaryMetadata;
import org.micromanager.PropertyMaps;

//acquisition parameter
pathRoot = "D:/data/20210716_fish_dualcolor/fish1_wholebody";
pathPrefix = "stage_TL200_range3200um_step0.310_6um_view3_interval_2s_20ms_30mW";
int num_ch = 2; // real color channel. For interleaved channel acquisition. reduce the step size by n for n-channel imaging. change the step
int num_view = 2;
String[] channels={"488", "561"}; // specify the channels for sequential multi-color imaging
boolean interleave = false;  // multi channel acquisition mode
// size in python code as well.

int nrFrames = 1;
double step = 0.310 * 6; // unit: um 0.310 * 4
double range = 3200; // unit: um
double interval = 2; // unit: s
int scanMode = 0;  // 0 for raster, 1 for serpantine
double customOffset = 420; // -260; // unit: um, offset between two views for better coverage
// negative value shifts the stage to left to focus more on the right side

//int nrChannels = num_view; // channels include view and channel, todo, add options for sequential channel imaging

// check channel information is correct
if (num_ch==1){
	interleave = true; //making sure that interleave is true for single color imaging
}
if (!interleave && (channels.length != num_ch)) {
	print("number of channels is not consistent!");
	num_ch = channels.length;
}

// for metadata store
double angle = 45;  // inciden angle
double res = 0.439; // xy pixel size, TTL100 0.439, TTL200 0.219, TTL300 0.146, TTL165 0.266

// positive offset value, shifting the view2 towards left
double alignmentOffset = 0; // 80 unit: um, offset between two views due to alignment
double galvoOffset = 0; // 140 unit: um, offset between two views due to different galvo values
double offset = alignmentOffset + galvoOffset + customOffset;

//pre-calculate parameters
int nrSlices = range / step;

// reset the scanning range for multi channel imaging
if (nrSlices % num_ch != 0 && interleave) {
	nrSlices = nrSlices - nrSlices % num_ch;
   range = nrSlices * step;
	}

print("number of slices: " + nrSlices);
double exposureMs = mmc.getExposure();
print("exposure time: " + exposureMs);
port = "COM6";
double speed = step / exposureMs;
DecimalFormat df = new DecimalFormat("#.####");
print("scan range (um): " + range);
//savePath
savePath = pathRoot + "/" + pathPrefix;
savePath = mm.data().getUniqueSaveDirectory(savePath);

// store data
store = mm.data().createMultipageTIFFDatastore(savePath, true, true);
mm.displays().createDisplay(store);

// SummaryMetadata
summary = mm.data().getSummaryMetadataBuilder();
summary.channelGroup("Channels");
String[] axisOrder = {"z", "channel", "time", "position"};
summary.axisOrder(axisOrder);
coorbuilder = mm.data().getCoordsBuilder().time(nrFrames).stagePosition(1).z(nrSlices).channel(num_view * num_ch);
summary.intendedDimensions(coorbuilder.build());
if (interleave){
	summary.zStepUm(step*num_ch); // real step in interleaved multicolor imaging is step * num_ch
}
else {
	summary.zStepUm(step);
}
myPropertyMap = PropertyMaps.builder().putInteger("angle", angle).putDouble("res", res).putInteger("view", num_view).putInteger("channel", num_ch).putInteger("pos", 1).build();
summary.userData(myPropertyMap);
store.setSummaryMetadata(summary.build());
       
// scan mode; 0 for raster, 1 for serpantine
message = "scan f=" + Integer.toString(scanMode);
mmc.setSerialPortCommand(port,message,"\r");
print(message);
		
//set backlash
message = "backlash x=0.04 y=0.0";
print("set backlash: " + message);
mmc.setSerialPortCommand(port,message,"\r");

//set speed
message = "speed x=" + df.format(speed);
print("set speed to scan: " + message);
mmc.setSerialPortCommand(port,message,"\r");

// set current position to zero
message = "zero";
mmc.setSerialPortCommand(port,message,"\r");

// Camera trigger settings
mmc.setProperty("HamamatsuHam_DCAM", "TRIGGER SOURCE", "EXTERNAL");
String propTRIG = mmc.getProperty("HamamatsuHam_DCAM", "TRIGGER SOURCE");
print("TRIGGER SOURCE:" + propTRIG);

mmc.setProperty("HamamatsuHam_DCAM", "TRIGGER DELAY", "0.0");
String propTRIG = mmc.getProperty("HamamatsuHam_DCAM", "TRIGGER DELAY");
print("TRIGGER DELAY:" + propTRIG);

// start acquistion
for (int f=0; f<nrFrames; f++){
		if (interleave) {
				for(int view=0; view<num_view; view++){	
					//acquire data while scanning move 400 um relative
					if (view==0) {
						message = "scanr x=0.0 y=" + range / 1000;
						print("scan range: " + message);
						mmc.setSerialPortCommand(port,message,"\r");
						message = "scanv x=0.0 y=0.0";
						mmc.setSerialPortCommand(port,message,"\r");
					}
					else {
						message = "scanr x=" + df.format((-offset) / 1000) + " y=" + df.format((-offset + range) / 1000);
						print("scan range: " + message);
						mmc.setSerialPortCommand(port,message,"\r");
						message = "scanv x=0.0 y=0.0";
						mmc.setSerialPortCommand(port,message,"\r");
					}
					print("scan range (um): " + range);

					print("start interleaved acquision: " + interleave);	
					mmc.startSequenceAcquisition(nrSlices, 0, true);
					builder = mm.data().getCoordsBuilder().z(0).channel(0).stagePosition(0);
					
					// start scan
					message = "scan";
					mmc.setSerialPortCommand(port,message,"\r");
					
					slice=0;
					
					while (mmc.getRemainingImageCount() > 0 || mmc.isSequenceRunning(mmc.getCameraDevice())) {
					   if (mmc.getRemainingImageCount() > 0) {
					   
					      tagged = mmc.popNextTaggedImage();
					      image = mm.data().convertTaggedImage(tagged,builder.time(f).channel(view).z(slice).build(), null);
					      store.putImage(image);
						   slice++;
					   }
					   else {
					      // Wait for another image to arrive.
					      mmc.sleep(Math.min(.5 * exposureMs, 20));
					   }
					}	
					mmc.stopSequenceAcquisition();
			
					mmc.sleep(Math.max(200, interval * 1000)); //wait until stage is back to original position
				}
		}
		else {
			for(int ch=0; ch<num_ch; ch++){
				// set the filter wheel to correct position
				mmc.setProperty("FilterWheel", "Label", channels[ch]);			
				print("set filter to: " + channels[ch]);	
				mmc.sleep(1000); //wait until filter wheel is settled

				for(int view=0; view<num_view; view++){	
					//acquire data while scanning move 400 um relative
					if (view==0) {
						message = "scanr x=0.0 y=" + range / 1000;
						print("scan range: " + message);
						mmc.setSerialPortCommand(port,message,"\r");
						message = "scanv x=0.0 y=0.0";
						mmc.setSerialPortCommand(port,message,"\r");
					}
					else {
						message = "scanr x=" + df.format((-offset) / 1000) + " y=" + df.format((-offset + range) / 1000);
						print("scan range: " + message);
						mmc.setSerialPortCommand(port,message,"\r");
						message = "scanv x=0.0 y=0.0";
						mmc.setSerialPortCommand(port,message,"\r");
					}
					print("scan range (um): " + range);
					
					mmc.startSequenceAcquisition(nrSlices, 0, true);
					builder = mm.data().getCoordsBuilder().z(0).channel(0).stagePosition(0);
					
					// start scan
					message = "scan";
					mmc.setSerialPortCommand(port,message,"\r");
					
					slice=0;
					
					while (mmc.getRemainingImageCount() > 0 || mmc.isSequenceRunning(mmc.getCameraDevice())) {
					   if (mmc.getRemainingImageCount() > 0) {
					   
					      tagged = mmc.popNextTaggedImage();
					      image = mm.data().convertTaggedImage(tagged,builder.time(f).channel(view*num_view + ch).z(slice).build(), null);
					      store.putImage(image);
						   slice++;
					   }
					   else {
					      // Wait for another image to arrive.
					      mmc.sleep(Math.min(.5 * exposureMs, 20));
					   }
					}	
					mmc.stopSequenceAcquisition();
					
					mmc.sleep(Math.max(200, interval * 1000)); //wait until stage is back to original position
				}
		}
	}
	
}

mmc.setProperty("HamamatsuHam_DCAM", "TRIGGER SOURCE", "INTERNAL");

//set default speed
message = "speed x=10 y=10";
mmc.setSerialPortCommand(port,message,"\r");

mm.displays().manage(store);

