import java.lang.String;
import java.text.DecimalFormat;
import org.micromanager.data.SummaryMetadata;
import org.micromanager.PropertyMaps;

//acquisition parameter
pathRoot = "D:/data/20220803_beads/TTL200_488_o1";
pathPrefix = "galvo_TL200_range40um_step0.4um_100ms_view1_TL0mmclosertoO2";

int num_ch = 1; // real color channel. For interleaved channel acquisition. reduce the step size by n for n-channel imaging. change the step
int num_view = 1;
boolean interleave = false;  // multi channel acquisition mode
// size in python code as well.

int nrFrames = 2;
double step = 0.155 * 3; // unit: um 0.310 * 4
double range = 40; // unit: um
double interval = 0; // unit: s
int scanMode = 0;  // 0 for raster, 1 for serpantine
double customOffset = 220; // -260; // unit: um, offset between two views for better coverage
// negative value shifts the stage to left to focus more on the right side

// for metadata store
double angle = 45;  // inciden angle
double res = 0.219; // xy pixel size, TTL100 0.439, TTL200 0.219, TTL300 0.146, TTL165 0.266

// check channel information is correct
if (num_ch==1){
	interleave = true; //making sure that interleave is true for single color imaging
}
if (!interleave && (channels.length != num_ch)) {
	print("number of channels is not consistent!");
	num_ch = channels.length;
}


// positive offset value, shifting the view2 towards left
double alignmentOffset = 0; // unit: um, offset between two views due to alignment
double galvoOffset = 0; // unit: um, offset between two views due to different galvo values
double offset = alignmentOffset + galvoOffset + customOffset;

//pre-calculate parameters
int nrSlices = range / step;

// reset the scanning range for multi channel imaging
if (nrSlices % num_ch != 0 && interleave) {
	nrSlices = nrSlices - nrSlices % num_ch;
   range = nrSlices * step;
	}
print("number of slices: " + nrSlices);
double exposureMs = mmc.getExposure();
print("exposure time: " + exposureMs);
double speed = step / exposureMs;
DecimalFormat df = new DecimalFormat("#.####");
print("scan range (um): " + range);
//savePath
savePath = pathRoot + "/" + pathPrefix;
savePath = mm.data().getUniqueSaveDirectory(savePath);

// store data
store = mm.data().createMultipageTIFFDatastore(savePath, true, true);
mm.displays().createDisplay(store);

// SummaryMetadata
summary = mm.data().getSummaryMetadataBuilder();
summary.channelGroup("Channels");
String[] axisOrder = {"z", "channel", "time", "position"};
summary.axisOrder(axisOrder);
coorbuilder = mm.data().getCoordsBuilder().time(nrFrames).stagePosition(1).z(nrSlices).channel(num_view * num_ch);
summary.intendedDimensions(coorbuilder.build());
summary.zStepUm(step*num_ch); // real step in multicolor imaging is step * num_ch
myPropertyMap = PropertyMaps.builder().putInteger("angle", angle).putDouble("res", res).putInteger("view", num_view).putInteger("channel", num_ch).putInteger("pos", 1).build();
summary.userData(myPropertyMap);
store.setSummaryMetadata(summary.build());
       
// start acquistion
for (int f=0; f<nrFrames; f++){
	for(int ch=0; ch<num_view; ch++){	
		mmc.startSequenceAcquisition(nrSlices, 0, true);
		builder = mm.data().getCoordsBuilder().z(0).channel(0).stagePosition(0);
		
		slice=0;
		
		while (mmc.getRemainingImageCount() > 0 || mmc.isSequenceRunning(mmc.getCameraDevice())) {
		   if (mmc.getRemainingImageCount() > 0) {
		   
		      tagged = mmc.popNextTaggedImage();
		      image = mm.data().convertTaggedImage(tagged,builder.time(f).channel(ch).z(slice).build(), null);
		      store.putImage(image);
			   slice++;
		   }
		   else {
		      // Wait for another image to arrive.
		      mmc.sleep(Math.min(.5 * exposureMs, 20));
		   }
		}	
		mmc.stopSequenceAcquisition();

		mmc.sleep(Math.max(200, interval * 1000)); //wait until stage is back to original position
	}
	
}

mm.displays().manage(store);

